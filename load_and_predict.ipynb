{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\duos8001\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "# Basic libraries\n",
    "import collections\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier\n",
    "from sklearn.preprocessing import LabelBinarizer, LabelEncoder\n",
    "\n",
    "#LGBM\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# System\n",
    "from os.path import join"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing the data\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path, subsampling=None, seed=17):\n",
    "    if subsampling:\n",
    "        data = pd.read_csv(path).sample(n=subsampling, random_state=seed)\n",
    "\n",
    "    else:\n",
    "        data = raw_data = pd.read_csv(path)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binarize(X:pd.DataFrame, columns):\n",
    "    \"\"\"Takes the X dataframe and binarizes given columns (transforms n given, not necessarily binary columns into m \n",
    "    binary columns, where m is not smaller than n)\n",
    "    \"\"\"\n",
    "\n",
    "    output = X.copy()\n",
    "    for col in columns:\n",
    "        binned_values = pd.get_dummies(output[col], drop_first=True)\n",
    "        binned_names = [col + '_' + str(x) for x in binned_values.columns]\n",
    "        binned_values.columns = binned_names\n",
    "        output = pd.concat([output, binned_values], axis=1)\n",
    "        output.drop(col, inplace=True, axis=1)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(X):\n",
    "    \"\"\"Takes the X dataframe and transforms values inside it into numeric type\n",
    "    \"\"\"\n",
    "    encoder = LabelEncoder()\n",
    "    output = X.copy()\n",
    "    for col in output.columns:\n",
    "        encoder.fit(output[col])\n",
    "        output[col] = encoder.transform(output[col])\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imput(df, by_cols, to_col, model=None):\n",
    "    \"\"\"Takes the df dataframe and imputs column given in to_col, based on values from columns given in by_cols. Optionally\n",
    "    the classifier to be used might be specified, if not KNN with k=100 is used.\n",
    "    \"\"\"\n",
    "    def imput_snippet(X, y, model):\n",
    "        no_nan_indeces = y.dropna().index\n",
    "        nan_indeces = y[y.isna()].index\n",
    "\n",
    "        model.fit(X.iloc[no_nan_indeces],\n",
    "                y.iloc[no_nan_indeces])\n",
    "\n",
    "        inputed_values = model.predict(X.iloc[nan_indeces])\n",
    "\n",
    "        return inputed_values\n",
    "\n",
    "    output = df.copy().reindex()\n",
    "\n",
    "    useful_idx = output[by_cols].dropna().index\n",
    "    to_input = output[to_col].iloc[useful_idx]\n",
    "    if model is not None:\n",
    "        clf = model\n",
    "    else:\n",
    "        clf = KNeighborsRegressor(n_neighbors=100)\n",
    "\n",
    "    nan_indeces = output.iloc[useful_idx][output[to_col].iloc[useful_idx].isnull()].index\n",
    "\n",
    "    output[to_col].iloc[nan_indeces] = imput_snippet(output[by_cols].iloc[useful_idx],\n",
    "                                        to_input,\n",
    "                                        clf)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def age_to_bins(age):\n",
    "    \"\"\"Degranulates the age columns into multiplications of 10\n",
    "    \"\"\"\n",
    "    return age%10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_target(data):\n",
    "    \"\"\"Fixes the wrongly assigned Target values. Target value (poverty level) should be the same for all habitants in a\n",
    "    household (denoted by column idhogar), so any row where the Target value is different from household's \n",
    "    head (denoted by column parentesco1==1) should be changed to be the same as the household's head's Target value\n",
    "    \"\"\"\n",
    "    def has_head(row):\n",
    "        same_household = data['idhogar'] == row['idhogar']\n",
    "        is_head = data['parentesco1'] == 1\n",
    "        return (same_household & is_head).any()\n",
    "\n",
    "    def get_true_target(row):\n",
    "        if pd.isnull(row['Target']):\n",
    "            return np.nan\n",
    "        else:\n",
    "            same_household = data['idhogar'] == row['idhogar']\n",
    "            is_head = data['parentesco1'] == 1\n",
    "            head = data[same_household & is_head]\n",
    "            return int(head['Target'])\n",
    "\n",
    "    df = data.copy()\n",
    "    df = df[df.apply(has_head, axis=1)]\n",
    "\n",
    "    not_head = df['parentesco1'] != 1\n",
    "    df.set_value(index=not_head[not_head].index,\n",
    "                 col='Target',\n",
    "                 value=df[not_head].apply(get_true_target, axis=1))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerate_yes_nos(row):\n",
    "    \"\"\"Transform string values 'yes' into 1's (int) and string values 'no' into 0's (int). If other value is given returns \n",
    "    float conversion of it.\n",
    "    \"\"\"\n",
    "    if row == 'yes':\n",
    "        return 1\n",
    "    elif row == 'no':\n",
    "        return 0\n",
    "    else:\n",
    "        return float(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_iterable(x):\n",
    "    \"\"\"Returns True if the given value is an iterable, but not a string\n",
    "    \"\"\"\n",
    "    if isinstance(x, str):\n",
    "        return False\n",
    "    elif isinstance(x, collections.Iterable):\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_features(X, y, n=None, verbose=0):\n",
    "    \"\"\"From the X dataframe returns n columns (features) that give best results in predicting values in y. RFE algorithm is \n",
    "    used for feature selection. Verbose paramter controls amount of response given by the algorithm.\n",
    "    \"\"\"\n",
    "    selector = RFE(RandomForestClassifier(n_estimators=150), n_features_to_select=n, verbose=verbose, step=2)\n",
    "    selector.fit(X, y)\n",
    "\n",
    "    return X.columns[selector.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(directory: str=None, filenames: str=None, to_binarize=True, to_numerate=True, to_imput=True,\n",
    "               to_select_feats = True):\n",
    "    \"\"\"Takes directory and filename of the training data. Return preprocessed data separated into X and y pd.Dataframes\n",
    "    \n",
    "    :str directory:\n",
    "    :str filename:\n",
    "    :bool to_binarize:\n",
    "    :bool to_numerate:\n",
    "    :bool to_imput:\n",
    "    :bool to_select_feats:\n",
    "    :return X:pd.Dataframe, y:pd.Dataframe:\n",
    "    \"\"\"\n",
    "    if directory is None:\n",
    "        directory = ''\n",
    "    if not is_iterable(filenames):\n",
    "        names = [filenames]\n",
    "    else:\n",
    "        names = filenames\n",
    "\n",
    "    # Read the csv file\n",
    "    if is_iterable(filenames):\n",
    "        data = pd.DataFrame([])\n",
    "        for name in names:\n",
    "            tmp = pd.read_csv(name)\n",
    "            if 'Target' not in tmp.columns:\n",
    "                tmp['Target'] = np.nan\n",
    "            data = pd.concat([tmp, data])\n",
    "    else:\n",
    "        data = pd.read_csv(join(directory, filenames))\n",
    "        if 'Target' not in data.columns:\n",
    "            data['Target'] = np.nan\n",
    "\n",
    "\n",
    "    # Shuffle the data and reset the index\n",
    "    data = fix_target(data)\n",
    "    data = data.sample(frac=1, random_state=17).reset_index()\n",
    "\n",
    "\n",
    "    # Split the data into dependent and independent vars and ids\n",
    "    X: pd.DataFrame = data.drop(['Target', 'Id'], axis=1).copy()\n",
    "    y: pd.Series = data['Target'].copy()\n",
    "    ids: pd.Series = data['Id']\n",
    "\n",
    "\n",
    "    # Convert data to numeric, where possible\n",
    "    if to_numerate is True:\n",
    "        le = LabelEncoder()\n",
    "        le.fit(X['idhogar'])\n",
    "\n",
    "        X.loc[:, 'idhogar'] = le.transform(X['idhogar'])\n",
    "        X.loc[:, 'edjefa'] = X['edjefa'].apply(numerate_yes_nos)\n",
    "        X.loc[:, 'edjefe'] = X['edjefe'].apply(numerate_yes_nos)\n",
    "        X.loc[:, 'dependency'] = X['dependency'].apply(numerate_yes_nos)\n",
    "        X.loc[:, 'age'] = X['age'].apply(age_to_bins)\n",
    "\n",
    "        print(\"Number of columns in X: \", len(X.columns))\n",
    "\n",
    "\n",
    "    # Imput nan values\n",
    "    if to_imput is True:\n",
    "        X.update(imput(X, ['SQBescolari'], 'meaneduc'), overwrite=True)\n",
    "        X.update(imput(X, ['meaneduc'], 'SQBmeaned'), overwrite=True)\n",
    "        X.update(imput(X, ['rooms', 'meaneduc','SQBmeaned', 'SQBedjefe'], 'v2a1'), overwrite=True)\n",
    "        X.update(imput(X, ['agesq', 'SQBage','age'], 'rez_esc', model=KNeighborsClassifier(n_neighbors=40)), overwrite=True)\n",
    "        X.loc[X.v18q1.isnull(), 'v18q1'] = 0\n",
    "\n",
    "        print(\"Number of columns in X: \", len(X.columns))\n",
    "\n",
    "\n",
    "    # Drop nan columns\n",
    "    X = X.dropna(axis=1)\n",
    "\n",
    "\n",
    "    # Drop non numeric columns\n",
    "    acc_dtypes = [np.int64, np.float64]\n",
    "    is_numeric = X.dtypes.apply(lambda x: x in acc_dtypes)\n",
    "    X = X[is_numeric.index[is_numeric]]\n",
    "\n",
    "\n",
    "\n",
    "    # Binarize the classes\n",
    "    if to_binarize is True:\n",
    "        cols_to_binarize = [x for x in X.columns if len(X[x].value_counts()) < 10]\n",
    "        X = binarize(X, cols_to_binarize)\n",
    "\n",
    "        print(\"Number of columns in X: \", len(X.columns))\n",
    "\n",
    "\n",
    "\n",
    "    # Feature selection\n",
    "    if to_select_feats is True:\n",
    "        selected_columns = select_features(X[y.notnull()], y[y.notnull()], n=200)\n",
    "        X = X[selected_columns]\n",
    "\n",
    "        print(\"Number of columns in X: \", len(X.columns))\n",
    "\n",
    "\n",
    "    return X, y, ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model creation and evaluation\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = LGBMClassifier(n_estimators=800)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_validate():\n",
    "    filename = 'train.csv'\n",
    "    X, y, ids = preprocess(filenames=[filename], to_binarize=True, to_select_feats=False)\n",
    "    print(\"Data loaded\")\n",
    "    model = get_model()\n",
    "    cross_f1 = cross_val_score(model, X, y, scoring='f1_macro', cv=5)\n",
    "    return cross_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict():\n",
    "    train_filename = 'train.csv'\n",
    "    test_filename = 'test.csv'\n",
    "    filenames = train_filename\n",
    "    print(\"Preprocessing the data\")\n",
    "    # X, y, ids = preprocess(filenames=filenames)\n",
    "    # test_idx = y[y.isnull()].index\n",
    "    # train_idx = y[y.notnull()].index\n",
    "    # X_train = X.iloc[train_idx]\n",
    "    # y_train = y.iloc[train_idx].astype(int)\n",
    "    # X_test = X.iloc[test_idx]\n",
    "    # test_ids = ids.iloc[test_idx]\n",
    "    X_train, y_train, ids_train = preprocess(filenames=train_filename, to_binarize=False, to_select_feats=False)\n",
    "    X_test, y_test, ids_test = preprocess(filenames=test_filename, to_binarize=False, to_select_feats=False)\n",
    "    X_test = X_test[X_train.columns.values]\n",
    "\n",
    "    head_idx = X_train['parentesco1'] == 1\n",
    "    reference = y_train[head_idx].copy()\n",
    "    reference.index = X_train[head_idx]['idhogar'].copy()\n",
    "    y_train = pd.concat([y_train, X_train], axis=1).apply(lambda x: fix_target(x, reference), axis=1)\n",
    "\n",
    "    selected_features = select_features(X_train, y_train, 100, verbose=1)\n",
    "    X_train = X_train[selected_features]\n",
    "    X_test = X_test[selected_features]\n",
    "\n",
    "    model = get_model()\n",
    "    print(\"Training the model\")\n",
    "    model.fit(X_train, y_train)\n",
    "    print(\"Predicting values\")\n",
    "    preds_arr = model.predict(X_test)\n",
    "    preds = pd.DataFrame({'Id' : ids_test,\n",
    "                       'Target' : preds_arr})\n",
    "    print(\"Prediction done\")\n",
    "    \n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_preds(filename=None):\n",
    "    preds:pd.DataFrame = predict()\n",
    "    if filename is None:\n",
    "        filename = 'predictions.csv'\n",
    "    preds.to_csv(filename, index=False, header=True)\n",
    "    print(\"File saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Script started on:  Tue Aug 21 15:00:56 2018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\duos8001\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:26: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns in X:  142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\duos8001\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:189: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns in X:  142\n",
      "Number of columns in X:  196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\duos8001\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\duos8001\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\duos8001\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\duos8001\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\duos8001\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    print(\"Script started on: \", time.asctime())\n",
    "    score = cv_validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validated, macro averaged f1 score of the prediction is 95.88%\n"
     ]
    }
   ],
   "source": [
    "print(\"Cross validated, macro averaged f1 score of the prediction is {:.2f}%\".format(100*np.mean(score)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
